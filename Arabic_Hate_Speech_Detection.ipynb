{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl-z0SH0gR_C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKFr-GcJjXEE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('AJGT.xlsx',header = 0)\n",
    "df = df[['Feed','Sentiment']]\n",
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "df.columns= [DATA_COLUMN,LABEL_COLUMN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFnvKJpojo2y"
   },
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHazBYgbAugR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class SADataset(Dataset):\n",
    "  def __init__(self, texts, labels, model_name, max_len, label_map):\n",
    "   \n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.label_map = label_map\n",
    "    self.tokenizer_name = model_name\n",
    "    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "   \n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    \n",
    "    text = str(self.texts[item])\n",
    "    label = self.labels[item]\n",
    "\n",
    "    input_dict = self.tokenizer(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          padding = 'max_length',\n",
    "          truncation= True\n",
    "      )\n",
    "\n",
    "    return InputFeatures(input_ids=input_dict[\"input_ids\"],\n",
    "                         token_type_ids=input_dict['token_type_ids'],\n",
    "                         attention_mask=input_dict[\"attention_mask\"],\n",
    "                         label=self.label_map[self.labels[item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGPOnvGZRlVT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    assert len(preds) == len(pred.label_ids)\n",
    "\n",
    "   \n",
    "    acc = accuracy_score(pred.label_ids, preds)\n",
    "    macro_f1 = f1_score(pred.label_ids, preds, average='macro')\n",
    "    macro_f1_pos_neg = f1_score(pred.label_ids, preds, labels=[0, 1], average='macro') # Adjust labels as needed\n",
    "    macro_precision = precision_score(pred.label_ids, preds, average='macro')\n",
    "    macro_recall = recall_score(pred.label_ids, preds, average='macro')\n",
    "\n",
    "    return {\n",
    "        'macro_f1': macro_f1,\n",
    "        'macro_f1_pos_neg': macro_f1_pos_neg,\n",
    "        'macro_precision': macro_precision,\n",
    "        'macro_recall': macro_recall,\n",
    "        'accuracy': acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbMtdGpB0t3w"
   },
   "outputs": [],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "arabert_prep = ArabertPreprocessor(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-wo9pTC0zXT"
   },
   "outputs": [],
   "source": [
    "data_train[DATA_COLUMN] = data_train[DATA_COLUMN].apply(lambda x: arabert_prep.preprocess(x))\n",
    "data_test[DATA_COLUMN] = data_test[DATA_COLUMN].apply(lambda x: arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDikUkPn2DqE",
    "outputId": "c0cbc453-24cd-4e03-ef11-b1f5d78d327a"
   },
   "outputs": [],
   "source": [
    "label_list = list(data_test[LABEL_COLUMN].unique())\n",
    "label_map = { v:index for index, v in enumerate(label_list) }\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2zr1L_31e5J"
   },
   "outputs": [],
   "source": [
    "max_len = 256\n",
    "train_dataset = SADataset(\n",
    "   texts = data_train[DATA_COLUMN].to_list(),\n",
    "   labels = data_train[LABEL_COLUMN].to_list(),\n",
    "   model_name = model_name,\n",
    "   max_len = 256,\n",
    "   label_map = label_map\n",
    ")\n",
    "\n",
    "test_dataset = SADataset(\n",
    "   texts = data_test[DATA_COLUMN].to_list(),\n",
    "   labels = data_test[LABEL_COLUMN].to_list(),\n",
    "   model_name = model_name,\n",
    "   max_len = 256,\n",
    "   label_map = label_map\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVUtKhfwiyMZ",
    "outputId": "c9fd8576-29a8-4ebb-99e9-d8598441d9b1"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "1BtOuUXX4JD0",
    "outputId": "0bf9d635-f417-40f9-f9a4-02a13d7b8acd"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./train\",\n",
    "    adam_epsilon=1e-8,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=8,\n",
    "    do_eval=True,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_macro_f1',\n",
    "    greater_is_better=True,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQ0Kxrs46QI9"
   },
   "outputs": [],
   "source": [
    "training_args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxuG93Aj5iiA"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "   model = model,\n",
    "   args = training_args,\n",
    "   train_dataset = train_dataset,\n",
    "   eval_dataset = test_dataset,\n",
    "   compute_metrics = compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvxxCSpI-yGG"
   },
   "source": [
    "#  Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPCX0NUt51wS"
   },
   "outputs": [],
   "source": [
    "trainer.model.config.label2id = label_map\n",
    "inv_label_map = { v:k for k, v in label_map.items()}\n",
    "trainer.model.config.id2label = inv_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1UFwVNs-6Dk"
   },
   "outputs": [],
   "source": [
    "#save the model in the folder\n",
    "trainer.save_model(\"best_sa_model\")\n",
    "test_dataset.tokenizer.save_pretrained(\"best_sa_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzTSG6cp_g36"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model = \"best_sa_model\",\n",
    "        device=0, \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aJegKHL_zjk"
   },
   "outputs": [],
   "source": [
    "pipe(\"انا لا احبك\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Sl3tW71-v92"
   },
   "outputs": [],
   "source": [
    "pipe(\"انا احبك\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESo3XXCHTpc4"
   },
   "outputs": [],
   "source": [
    "pipe(\"  الاكل ما عجبني للاسف\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeABft6CTtg1"
   },
   "outputs": [],
   "source": [
    "pipe(\" جميل\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kX_zw2pcsccO"
   },
   "outputs": [],
   "source": [
    "pipe(\" الخدمة كانت كب شينة لكن موخرا صارت سيئة\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"خدمة العملاء أكثر من مرة اتصل عليهم ولا يحلون لي مشكلتي\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"دكتور سلطان يده خفيفة جدا ما شاء الله\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"الدكتور درسني في الجامعة فمة في الخلق والتواضع \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvFB_jFGTuWe"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# from google.colab import files\n",
    "\n",
    "# # Compress the model directory into a zip file\n",
    "# shutil.make_archive('best_sa_model', 'zip', 'best_sa_model')\n",
    "\n",
    "# # Download the zip file\n",
    "# files.download('best_sa_model.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3dUmH90Thx6"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # save the iris classification model as a pickle file\n",
    "# model_pkl_file = \"AHSP_v0\"\n",
    "\n",
    "# with open(model_pkl_file, 'wb') as file:\n",
    "#     pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7P6IqOo3P7x"
   },
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # save model with joblib\n",
    "# filename = 'joblib_model.sav'\n",
    "# joblib.dump(model, filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
